{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXx+oKLK+yo2KUuoRRs8Bh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/webb-e/S2_Landsat_Comparison/blob/main/ConcatRegions_cleandata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "## import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n"
      ],
      "metadata": {
        "id": "1lsPPBhcPmS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPT9xLi1PRhY"
      },
      "outputs": [],
      "source": [
        "# List all files starting with 'analysis ready'\n",
        "files = glob.glob('ALPOD/Lakewise_csvs/analysis_ready_*')\n",
        "\n",
        "# Read and concatenate all the files\n",
        "df = pd.concat([pd.read_csv(file) for file in files], ignore_index=True)\n",
        "\n",
        "# Display the combined DataFrame\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### remove lakes where S2 max is zero, or where Pickens and Pekel are both zero\n",
        "### these tend to not be real lakes\n",
        "data = df[df['S2max'] != 0]\n",
        "data = data[~((data['Landsat_Pekel'] == 0) & (data['Landsat_Pickens'] == 0))]"
      ],
      "metadata": {
        "id": "bUJ0x4WSPlir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## get the sum of water for each year in each region\n",
        "sum_by_year = data.groupby(['year', 'region'])['S2max'].sum().reset_index()\n",
        "### get the percentage of the year with the maximum water extent\n",
        "sum_by_year['max_value'] = sum_by_year.groupby(['region'])['S2max'].transform('max')\n",
        "sum_by_year['proportion_of_max'] = (sum_by_year['S2max'] / sum_by_year['max_value'])\n",
        "## join back with original dataframe\n",
        "dataframe = data.merge(sum_by_year[['year', 'region', 'proportion_of_max']], on=['year', 'region'], how='left')\n",
        "dataframe.head()"
      ],
      "metadata": {
        "id": "pQtiY2uXPV-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## remove lakes where error is >4 standard deviations from the mean\n",
        "print(f\"Number of rows before: {len(dataframe)}\")\n",
        "errorcols = ['Pickens_error_abs', 'Pekel_error_abs']\n",
        "\n",
        "# Apply the transformation\n",
        "for col in errorcols:\n",
        "    col_mean = dataframe[col].mean(skipna=True)\n",
        "    col_std = dataframe[col].std(skipna=True)\n",
        "    # Keep rows where values are within 4 standard deviations\n",
        "    dat = dataframe[(dataframe[col] - col_mean).abs() <= 4 * col_std]\n",
        "\n",
        "print(f\"Number of rows after: {len(dat)}\")"
      ],
      "metadata": {
        "id": "bbs3kAfkheAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of rows before: {len(dat)}\")\n",
        "filtered_data = (\n",
        "    dat\n",
        "    # Filter rows where specified columns are not NaN\n",
        "    .dropna(subset=[\"Landsat_Pekel\", \"Landsat_Pickens\"])\n",
        "    # Group by `lake_id`\n",
        "    .groupby(\"lake_id\")\n",
        "    # Filter groups with at least 6 rows\n",
        "    .filter(lambda group: len(group) >= 6)\n",
        "    # Ungroup by resetting the index\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "print(f\"Number of rows after: {len(filtered_data)}\")"
      ],
      "metadata": {
        "id": "WsH5ecNjwiTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## save to csv\n",
        "filtered_data.to_csv('ALPOD/Lakewise_csvs/Landsat_analysis_data.csv', index=False)"
      ],
      "metadata": {
        "id": "ztY1NimlVm1L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}