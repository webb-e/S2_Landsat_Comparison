{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyME9yGrLlswV8aubPhi2QD1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/webb-e/S2_Landsat_Comparison/blob/main/Landsat_lake_wise_export.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbRcSk060H1y",
        "outputId": "bbf92ae4-0de9-49f8-f1db-a910ad2e0acc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Authenticate private account (only required for exporting to drive/gee/gcp)\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Earth Engine setup\n",
        "import ee # Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project=\" \") # Initialize the library.\n",
        "\n",
        "# Google Drive setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Load in Landsat products\n",
        "## special loading of pickens collection since 2021 doesn't have the correct metadata\n",
        "pickenscollection = ee.ImageCollection(\"projects/glad/water/annual\")\n",
        "imageList = pickenscollection.toList(pickenscollection.size())\n",
        "last6Images = imageList.slice(pickenscollection.size().subtract(6), pickenscollection.size());\n",
        "pickens_collection = ee.ImageCollection(last6Images).map(lambda img: img.rename(['wp']))\n",
        "\n",
        "\n",
        "### pekel\n",
        "pekel_collection = ee.ImageCollection(\"JRC/GSW1_4/YearlyHistory\").filter(ee.Filter.date('2016-01-01', '2021-12-31'))\n",
        "\n",
        "### define region info\n",
        "lakeshp = None\n",
        "region_label = None\n",
        "def regionfun(region):\n",
        "  global  lakeshp, region_label\n",
        "  if region == 'TUK':\n",
        "    lakeshp = ee.FeatureCollection(\"projects/alpod-412314/assets/Lake_extractions/TUK_extraction\")\n",
        "    region_label = 'TUK'\n",
        "  elif region == 'AND':\n",
        "    lakeshp = ee.FeatureCollection(\"projects/alpod-412314/assets/Lake_extractions/AND_extraction\")\n",
        "    region_label = 'AND'\n",
        "  elif region == 'MRD':\n",
        "    lakeshp = ee.FeatureCollection(\"projects/alpod-412314/assets/Lake_extractions/MRD_extraction\")\n",
        "    region_label = 'MRD'\n",
        "  elif region == 'AKCP':\n",
        "    lakeshp = ee.FeatureCollection(\"projects/alpod-412314/assets/Lake_extractions/AKCP_extraction\")\n",
        "    region_label = 'AKCP'\n",
        "  elif region == 'YKD':\n",
        "    lakeshp = ee.FeatureCollection(\"projects/alpod-412314/assets/Lake_extractions/YKD_extraction\")\n",
        "    region_label = 'YKD'\n",
        "  elif region == 'YKF':\n",
        "    lakeshp = ee.FeatureCollection(\"projects/alpod-412314/assets/Lake_extractions/YKF_extraction\")\n",
        "    region_label = 'YKF'\n",
        "  else:\n",
        "    print(\"Invalid region\")"
      ],
      "metadata": {
        "id": "D5JSxfe1K9hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this code for all regions except the MRD, which will time out due to memory issues; MRD code is below."
      ],
      "metadata": {
        "id": "t0j4ZuHLhQfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## choose region\n",
        "regionfun('TUK') # options = TUK,AND, AKCP, YKD, YKF\n",
        "\n",
        "############\n",
        "###### PICKENS\n",
        "############\n",
        "def pickens_fun(image):\n",
        "  ## get image year\n",
        "  pickensyear = ee.String(image.get('system:id'))\n",
        "  year = pickensyear.split('/').get(4)\n",
        "  ## unmask and get binary image (masked/notmasked)\n",
        "  maskedimg = image.unmask(-1).eq(-1).clip(lakeshp)\n",
        "  ## get total number of pixels in region\n",
        "  totalimg = image.unmask(-1).gte(-1).clip(lakeshp)\n",
        "  ## clip to lake shapefile and create a binary image\n",
        "  waterimg = image.clip(lakeshp).gt(0)\n",
        "  ## get area of water\n",
        "  waterarea = waterimg.multiply(ee.Image.pixelArea())\n",
        "  ## get area of masked\n",
        "  maskedarea = maskedimg.multiply(ee.Image.pixelArea())\n",
        "  ## total area of region\n",
        "  totalarea = totalimg.multiply(ee.Image.pixelArea())\n",
        "  ## add bands\n",
        "  areaImage = waterarea.addBands(maskedarea).addBands(totalarea)\n",
        "  ## sum water, masked, and total areas\n",
        "  reduceroutput =  areaImage.reduceRegions(collection=  lakeshp,\n",
        "                                                scale = 30,\n",
        "                                                reducer = ee.Reducer.sum())\n",
        "    ## add feature properties to output\n",
        "  def pickens_dealwithoutput(f):\n",
        "    waterarea = ee.Number(f.get('wp'))#.divide(1e6).round()\n",
        "    maskedarea = ee.Number(f.get('wp_1')).round()\n",
        "    totalarea = ee.Number(f.get('wp_2')).round()\n",
        "    unmaskedarea = totalarea.subtract(maskedarea)\n",
        "    permasked = maskedarea.divide(totalarea).multiply(100).round()\n",
        "    return f.set({\"year\" : year, \"Landsat_Pickens\": waterarea, \"percent_masked\":permasked})\n",
        "\n",
        "  results = reduceroutput.map(pickens_dealwithoutput)\n",
        "  return results.filter(ee.Filter.eq('percent_masked', 0))\n",
        "\n",
        "pickens_intermediate = pickens_collection.map(pickens_fun)\n",
        "pickens_results = ee.FeatureCollection(pickens_intermediate).flatten()\n",
        "\n",
        "\n",
        "  #############\n",
        "  ###### PEKEL\n",
        "  ############\n",
        "def pekel_fun(image):\n",
        "  ## get image year\n",
        "  pekyear = ee.String(image.get('system:id'))\n",
        "  year = pekyear.split('/').get(3)\n",
        "  ## clip to lake shapefile and create a binary image\n",
        "                                  ## 0 = no observations\n",
        "                                  ## 1 = not water\n",
        "                                  ## 2 = seasonal water\n",
        "                                  ## 3 = permanent water\n",
        "  clipimage = image.clip(lakeshp)\n",
        "  waterimg = clipimage.eq(2).Or(clipimage.eq(3))\n",
        "  ## get values with no observations\n",
        "  noobs = image.eq(0).clip(lakeshp).multiply(ee.Image.pixelArea())\n",
        "  ## get total area\n",
        "  totalarea = image.gte(0).clip(lakeshp).multiply(ee.Image.pixelArea())\n",
        "  ## get area of water\n",
        "  waterarea = waterimg.multiply(ee.Image.pixelArea())\n",
        "  areaImage = waterarea.addBands(noobs).addBands(totalarea)\n",
        "  reduceroutput =  areaImage.reduceRegions(collection = lakeshp,\n",
        "                                                scale = 30,\n",
        "                                                reducer = ee.Reducer.sum())\n",
        "\n",
        "    ## add feature properties to  output and convert m2 to km2\n",
        "  def pekeloutput(f):\n",
        "    waterarea = ee.Number(f.get('waterClass'))#.divide(1e6).round()\n",
        "    maskedarea = ee.Number(f.get('waterClass_1'))#.divide(1e6).round()\n",
        "    totalarea = ee.Number(f.get('waterClass_2')).divide(1e6).round()\n",
        "    unmaskedarea = totalarea.subtract(maskedarea)\n",
        "    permasked = maskedarea.divide(totalarea).multiply(100).round()\n",
        "    return f.set({\"year\" : year ,  \"Landsat_Pekel\": waterarea,  \"percent_masked\":permasked})\n",
        "\n",
        "  results = reduceroutput.map(pekeloutput)\n",
        "  return results.filter(ee.Filter.eq('percent_masked', 0))\n",
        "\n",
        "pekel_intermediate = pekel_collection.map(pekel_fun)\n",
        "pekel_results = ee.FeatureCollection(pekel_intermediate).flatten()\n",
        "\n",
        "  #############\n",
        "  ###### PUT TOGETHER AND EXPORT\n",
        "  ############\n",
        "allresults = ee.FeatureCollection([pekel_results,  pickens_results]).flatten();\n",
        "\n",
        "description = 'Landsat_lake_areas_' + str(region_label)\n",
        "task = ee.batch.Export.table.toDrive(**{\n",
        "          'collection': allresults,\n",
        "          'selectors': ['year', 'Landsat_Pekel', 'Landsat_Pickens', 'lake_id'],\n",
        "          'folder': 'Lakewise_csvs',\n",
        "          'description': description,\n",
        "          'fileFormat': 'CSV',\n",
        "    })\n",
        "task.start()"
      ],
      "metadata": {
        "id": "RTW6ZEXNf2uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RUN THIS FOR THE MRD\n",
        "if you use the above code, it will run into memory issues"
      ],
      "metadata": {
        "id": "zqPzQ4_Jg5_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define chunk size\n",
        "regionfun('MRD')\n",
        "chunk_size = 1000\n",
        "\n",
        "def split_feature_collection(fc, chunk_size):\n",
        "    # Get the total number of features in the collection\n",
        "    num_features = fc.size().getInfo()\n",
        "\n",
        "    # Calculate the number of chunks\n",
        "    num_chunks = (num_features + chunk_size - 1) // chunk_size\n",
        "\n",
        "    # Create a list of chunks\n",
        "    chunks = []\n",
        "    for i in range(num_chunks):\n",
        "        # Use slice() to get the desired chunk\n",
        "        chunk = fc.toList(num_features).slice(i * chunk_size, (i + 1) * chunk_size)\n",
        "        chunks.append(ee.FeatureCollection(chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Split the FeatureCollection into chunks\n",
        "chunks = split_feature_collection(lakeshp, chunk_size)\n",
        "\n",
        "# Print the first chunk (or any chunk you want to inspect)\n",
        "print(len(chunks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AFgiKTHMcg8",
        "outputId": "6b71a109-9917-4ba7-d325-d277cb89ad1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_list = chunks[6:8]\n",
        "sub_list = ee.FeatureCollection(sub_list).flatten()\n",
        "chunksize = 500\n",
        "\n",
        "def split_feature_collection(fc, chunk_size):\n",
        "    # Get the total number of features in the collection\n",
        "    num_features = fc.size().getInfo()\n",
        "\n",
        "    # Calculate the number of chunks\n",
        "    num_chunks = (num_features + chunksize - 1) // chunksize\n",
        "\n",
        "    # Create a list of chunks\n",
        "    chunks = []\n",
        "    for i in range(num_chunks):\n",
        "        # Use slice() to get the desired chunk\n",
        "        chunk = fc.toList(num_features).slice(i * chunksize, (i + 1) * chunksize)\n",
        "        chunks.append(ee.FeatureCollection(chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Split the FeatureCollection into chunks\n",
        "chunks2 = split_feature_collection(sub_list, chunksize)\n"
      ],
      "metadata": {
        "id": "v4LK_ev-lvoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_list2 = chunks2[1:3]\n",
        "sub_list2 = ee.FeatureCollection(sub_list2).flatten()\n",
        "chunksize2 = 50\n",
        "\n",
        "def split_feature_collection(fc, chunksize2):\n",
        "    # Get the total number of features in the collection\n",
        "    num_features = fc.size().getInfo()\n",
        "\n",
        "    # Calculate the number of chunks\n",
        "    num_chunks = (num_features + chunksize2 - 1) // chunksize2\n",
        "\n",
        "    # Create a list of chunks\n",
        "    chunks = []\n",
        "    for i in range(num_chunks):\n",
        "        # Use slice() to get the desired chunk\n",
        "        chunk = fc.toList(num_features).slice(i * chunksize2, (i + 1) * chunksize2)\n",
        "        chunks.append(ee.FeatureCollection(chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Split the FeatureCollection into chunks\n",
        "chunks3 = split_feature_collection(sub_list2, chunksize2)"
      ],
      "metadata": {
        "id": "odmCbNYd0mDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_list3 = chunks3[11:13]\n",
        "sub_list3 = ee.FeatureCollection(sub_list3).flatten()\n",
        "chunksize3 = 10\n",
        "\n",
        "def split_feature_collection(fc, chunksize3):\n",
        "    # Get the total number of features in the collection\n",
        "    num_features = fc.size().getInfo()\n",
        "\n",
        "    # Calculate the number of chunks\n",
        "    num_chunks = (num_features + chunksize3 - 1) // chunksize3\n",
        "\n",
        "    # Create a list of chunks\n",
        "    chunks = []\n",
        "    for i in range(num_chunks):\n",
        "        # Use slice() to get the desired chunk\n",
        "        chunk = fc.toList(num_features).slice(i * chunksize3, (i + 1) * chunksize3)\n",
        "        chunks.append(ee.FeatureCollection(chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Split the FeatureCollection into chunks\n",
        "chunks4 = split_feature_collection(sub_list3, chunksize3)"
      ],
      "metadata": {
        "id": "bWKmqkLCDB30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_list4 = chunks4[6:7]\n",
        "sub_list4 = ee.FeatureCollection(sub_list4).flatten()\n",
        "chunksize4 = 1\n",
        "\n",
        "def split_feature_collection(fc, chunksize4):\n",
        "    # Get the total number of features in the collection\n",
        "    num_features = fc.size().getInfo()\n",
        "\n",
        "    # Calculate the number of chunks\n",
        "    num_chunks = (num_features + chunksize4 - 1) // chunksize4\n",
        "\n",
        "    # Create a list of chunks\n",
        "    chunks = []\n",
        "    for i in range(num_chunks):\n",
        "        # Use slice() to get the desired chunk\n",
        "        chunk = fc.toList(num_features).slice(i * chunksize4, (i + 1) * chunksize4)\n",
        "        chunks.append(ee.FeatureCollection(chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Split the FeatureCollection into chunks\n",
        "chunks5 = split_feature_collection(sub_list4, chunksize4)"
      ],
      "metadata": {
        "id": "Y5zcWct1zQif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run once for each chunk (chunks, chunks2, chunks3, chunks4, chunks5)"
      ],
      "metadata": {
        "id": "KwiJhP9dhDj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## choose region\n",
        "#regionfun('MRD') # options = TUK, MRD, AND, AKCP, YKD, YKF\n",
        "\n",
        "for index, lakeshp in enumerate(chunks5):\n",
        "\n",
        "  #############\n",
        "  ###### PICKENS\n",
        "  ############\n",
        "  def pickens_fun(image):\n",
        "  ## get image year\n",
        "    pickensyear = ee.String(image.get('system:id'))\n",
        "    year = pickensyear.split('/').get(4)\n",
        "  ## unmask and get binary image (masked/notmasked)\n",
        "    maskedimg = image.unmask(-1).eq(-1).clip(lakeshp)\n",
        "  ## get total number of pixels in region\n",
        "    totalimg = image.unmask(-1).gte(-1).clip(lakeshp)\n",
        "  ## clip to lake shapefile and create a binary image\n",
        "    waterimg = image.clip(lakeshp).gt(0)\n",
        "  ## get area of water\n",
        "    waterarea = waterimg.multiply(ee.Image.pixelArea())\n",
        "  ## get area of masked\n",
        "    maskedarea = maskedimg.multiply(ee.Image.pixelArea())\n",
        "  ## total area of region\n",
        "    totalarea = totalimg.multiply(ee.Image.pixelArea())\n",
        "  ## add bands\n",
        "    areaImage = waterarea.addBands(maskedarea).addBands(totalarea)\n",
        "  ## sum water, masked, and total areas\n",
        "    reduceroutput =  areaImage.reduceRegions(collection=  lakeshp,\n",
        "                                                scale = 30,\n",
        "                                                reducer = ee.Reducer.sum())\n",
        "  ## add feature properties to output\n",
        "    def pickens_dealwithoutput(f):\n",
        "      waterarea = ee.Number(f.get('wp'))#.divide(1e6).round()\n",
        "      maskedarea = ee.Number(f.get('wp_1')).round()\n",
        "      totalarea = ee.Number(f.get('wp_2')).round()\n",
        "      unmaskedarea = totalarea.subtract(maskedarea)\n",
        "      permasked = maskedarea.divide(totalarea).multiply(100).round()\n",
        "      return f.set({\"year\" : year, \"Landsat_Pickens\": waterarea, \"percent_masked\":permasked})\n",
        "\n",
        "    results = reduceroutput.map(pickens_dealwithoutput)\n",
        "    return results.filter(ee.Filter.eq('percent_masked', 0))\n",
        "\n",
        "  pickens_intermediate = pickens_collection.map(pickens_fun)\n",
        "  pickens_results = ee.FeatureCollection(pickens_intermediate).flatten()\n",
        "\n",
        "  #############\n",
        "  ###### PEKEL\n",
        "  ############\n",
        "  def pekel_fun(image):\n",
        "  ## get image year\n",
        "    pekyear = ee.String(image.get('system:id'))\n",
        "    year = pekyear.split('/').get(3)\n",
        "  ## clip to lake shapefile and create a binary image\n",
        "                                  ## 0 = no observations\n",
        "                                  ## 1 = not water\n",
        "                                  ## 2 = seasonal water\n",
        "                                  ## 3 = permanent water\n",
        "    clipimage = image.clip(lakeshp)\n",
        "    waterimg = clipimage.eq(2).Or(clipimage.eq(3))\n",
        "  ## get values with no observations\n",
        "    noobs = image.eq(0).clip(lakeshp).multiply(ee.Image.pixelArea())\n",
        "  ## get total area\n",
        "    totalarea = image.gte(0).clip(lakeshp).multiply(ee.Image.pixelArea())\n",
        "  ## get area of water\n",
        "    waterarea = waterimg.multiply(ee.Image.pixelArea())\n",
        "    areaImage = waterarea.addBands(noobs).addBands(totalarea)\n",
        "    reduceroutput =  areaImage.reduceRegions(collection = lakeshp,\n",
        "                                                scale = 30,\n",
        "                                                reducer = ee.Reducer.sum())\n",
        "  ## add feature properties to  output and convert m2 to km2\n",
        "    def pekeloutput(f):\n",
        "      waterarea = ee.Number(f.get('waterClass'))#.divide(1e6).round()\n",
        "      maskedarea = ee.Number(f.get('waterClass_1'))#.divide(1e6).round()\n",
        "      totalarea = ee.Number(f.get('waterClass_2')).divide(1e6).round()\n",
        "      unmaskedarea = totalarea.subtract(maskedarea)\n",
        "      permasked = maskedarea.divide(totalarea).multiply(100).round()\n",
        "      return f.set({\"year\" : year ,  \"Landsat_Pekel\": waterarea,  \"percent_masked\":permasked})\n",
        "\n",
        "    results = reduceroutput.map(pekeloutput)\n",
        "    return results.filter(ee.Filter.eq('percent_masked', 0))\n",
        "\n",
        "  pekel_intermediate = pekel_collection.map(pekel_fun)\n",
        "  pekel_results = ee.FeatureCollection(pekel_intermediate).flatten()\n",
        "\n",
        "  #############\n",
        "  ###### PUT TOGETHER AND EXPORT\n",
        "  ############\n",
        "  allresults = ee.FeatureCollection([pekel_results, pickens_results]).flatten();\n",
        "\n",
        "  description = 'Landsat_lake_areas_' + str(region_label) + '_chunk5_' + f\"{index}\"\n",
        "  task = ee.batch.Export.table.toDrive(**{\n",
        "          'collection': allresults,\n",
        "          'selectors': ['year', 'Landsat_Pekel', 'Landsat_Pickens', 'lake_id'],\n",
        "          'folder': 'Landsat_MRD_chunks',\n",
        "          'description': description,\n",
        "          'fileFormat': 'CSV',\n",
        "    })\n",
        "  task.start()"
      ],
      "metadata": {
        "id": "X_yCoDlS0_W4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
